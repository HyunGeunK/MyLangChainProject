{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79bfed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 1ë‹¨ê³„: ì´ˆê¸° ì„¤ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "ì´ˆê¸° ì„¤ì • ì™„ë£Œ!\n",
      "\n",
      "[ë…¸ë“œ: classify_input]\n",
      "'ì¸ê¸°ë©”ë‰´' -> ë¶„ë¥˜: menu\n",
      "\n",
      "[ë…¸ë“œ: search_menu]\n",
      "ASSISTANT: ì¸ê¸° ë©”ë‰´ë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì»¤í”¼ë“¤ì´ ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "1. **ì•„ë©”ë¦¬ì¹´ë…¸**: â‚©4,500\n",
      "   - ì›ë‘ ë³¸ì—°ì˜ ë§›ì„ ê°€ì¥ ì˜ ëŠë‚„ ìˆ˜ ìˆëŠ” í´ë˜ì‹í•œ ë¸”ë™ ì»¤í”¼ì…ë‹ˆë‹¤.\n",
      "\n",
      "2. **ì¹´í˜ë¼ë–¼**: â‚©5,500\n",
      "   - ëŒ€í‘œì ì¸ ë°€í¬ ì»¤í”¼ë¡œ í¬ë¦¬ë¯¸í•œ ì§ˆê°ê³¼ ë¶€ë“œëŸ¬ìš´ ë§›ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.\n",
      "\n",
      "3. **ì¹´í‘¸ì¹˜ë…¸**: â‚©5,000\n",
      "   - ì´íƒˆë¦¬ì•„ ì „í†µ ì»¤í”¼ë¡œ ì§„í•œ ì»¤í”¼ ë§›ê³¼ ë¶€ë“œëŸ¬ìš´ ìš°ìœ  ê±°í’ˆì˜ ì¡°í™”ê°€ ì¼í’ˆì…ë‹ˆë‹¤.\n",
      "\n",
      "4. **ë°”ë‹ë¼ ë¼ë–¼**: â‚©6,000\n",
      "   - ì¹´í˜ë¼ë–¼ì— ë‹¬ì½¤í•œ ë°”ë‹ë¼ ì‹œëŸ½ì„ ë”í•œ ì¸ê¸° ë©”ë‰´ë¡œ, ë°”ë‹ë¼ì˜ ë‹¬ì½¤í•¨ê³¼ ì»¤í”¼ì˜ ìŒ‰ì‹¸ë¦„í•¨ì´ ì¡°í™”ë¡­ê²Œ ì–´ìš°ëŸ¬ì§‘ë‹ˆë‹¤.\n",
      "\n",
      "5. **ì¹´ë¼ë©œ ë§ˆí‚¤ì•„í† **: â‚©6,500\n",
      "   - ìŠ¤íŒ€ ë°€í¬ ìœ„ì— ì—ìŠ¤í”„ë ˆì†Œë¥¼ ë¶€ì–´ ë§Œë“  í›„ ì¹´ë¼ë©œ ì‹œëŸ½ê³¼ íœ˜í•‘í¬ë¦¼ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•œ ë‹¬ì½¤í•œ ì»¤í”¼ì…ë‹ˆë‹¤.\n",
      "\n",
      "6. **í”„ë¼í‘¸ì¹˜ë…¸**: â‚©7,000\n",
      "   - ì—ìŠ¤í”„ë ˆì†Œì™€ ìš°ìœ , ì–¼ìŒì„ ë¸”ë Œë”ì— ê°ˆì•„ ë§Œë“  ì‹œì›í•œ ìŒë£Œë¡œ, ë¶€ë“œëŸ½ê³  í¬ë¦¬ë¯¸í•œ ì§ˆê°ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.\n",
      "\n",
      "7. **í‹°ë¼ë¯¸ìˆ˜**: â‚©7,500\n",
      "   - ì´íƒˆë¦¬ì•„ ì „í†µ ë””ì €íŠ¸ë¡œ ë¶€ë“œëŸ½ê³  ë‹¬ì½¤í•œ ë§›ì´ íŠ¹ì§•ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ë©”ë‰´ë“¤ì€ ê°ê°ì˜ ë…íŠ¹í•œ ë§›ê³¼ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆì–´ ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ ì‚¬ë‘ë°›ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "[ë…¸ë“œ: classify_input]\n",
      "'ì•„ë©”ë¦¬ì¹´ ê°€ê²©' -> ë¶„ë¥˜: price\n",
      "\n",
      "[ë…¸ë“œ: search_price]\n",
      "ASSISTANT: ì•„ë©”ë¦¬ì¹´ë…¸ì˜ ê°€ê²©ì€ â‚©4,500ì…ë‹ˆë‹¤.\n",
      "\n",
      "[ë…¸ë“œ: classify_input]\n",
      "'ë' -> ë¶„ë¥˜: general\n",
      "\n",
      "[ë…¸ë“œ: general_response]\n",
      "ASSISTANT: ì•ˆë…•í•˜ì„¸ìš”! ì¹´í˜ ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ì—¬ëŸ¬ë¶„ì´ í¸ì•ˆí•˜ê³  ì¦ê±°ìš´ ì‹œê°„ì„ ë³´ë‚´ì‹¤ ìˆ˜ ìˆë„ë¡ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì–´ë–¤ ìŒë£Œë¥¼ ì£¼ë¬¸í•˜ì‹œê² ì–´ìš”? ì»¤í”¼, ì°¨, ìŠ¤ë¬´ë”” ë“± ë‹¤ì–‘í•œ ë©”ë‰´ê°€ ì¤€ë¹„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ê°„ì‹ì´ë‚˜ ë””ì €íŠ¸ë„ í•¨ê»˜ ì¶”ì²œí•´ ë“œë¦´ ìˆ˜ ìˆì–´ìš”.\n",
      "\n",
      "í˜¹ì‹œ ì¹´í˜ì—ì„œ ì œê³µí•˜ëŠ” ì™€ì´íŒŒì´ë¥¼ ì‚¬ìš©í•˜ì‹œë ¤ë©´ ë¹„ë°€ë²ˆí˜¸ê°€ í•„ìš”í•˜ì‹ ê°€ìš”? ì•„ë‹ˆë©´ ë‹¤ë¥¸ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "ëì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ë³´ì…¨ìœ¼ë‹ˆ, ì˜¤ëŠ˜ì€ ì–´ë–¤ í•˜ë£¨ë¥¼ ë³´ë‚´ì…¨ëŠ”ì§€ ê¶ê¸ˆí•˜ë„¤ìš”. ì¢‹ì€ ì¼ì´ ìˆì—ˆë‚˜ìš”, ì•„ë‹ˆë©´ íŠ¹ë³„í•œ ê³„íšì´ ìˆìœ¼ì‹ ê°€ìš”? ëŒ€í™”ë¥¼ í†µí•´ ì„œë¡œì— ëŒ€í•´ ì¢€ ë” ì•Œì•„ê°€ëŠ” ê²ƒë„ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”.\n",
      "\n",
      "[ë…¸ë“œ: classify_input]\n",
      "'' -> ë¶„ë¥˜: general\n",
      "\n",
      "[ë…¸ë“œ: general_response]\n",
      "ASSISTANT: ë¬¼ë¡ ì´ì£ ! ì €í¬ ì¹´í˜ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. ì–´ë–¤ ìŒë£Œë‚˜ ë””ì €íŠ¸ë¥¼ ì°¾ìœ¼ì‹œëŠ”ì§€ ë„ì™€ë“œë¦´ê¹Œìš”? ì €í¬ëŠ” ë‹¤ì–‘í•œ ì»¤í”¼ ë©”ë‰´, ì°¨, ìˆ˜ì œ ì£¼ìŠ¤, ê·¸ë¦¬ê³  ë§›ìˆëŠ” ì¼€ì´í¬ì™€ í˜ì´ìŠ¤íŠ¸ë¦¬ë¥¼ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹ë³„í•œ ì¶”ì²œì„ ì›í•˜ì‹œê±°ë‚˜ ì•Œë ˆë¥´ê¸°ë‚˜ ì„ í˜¸ë„ê°€ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ì£¼ì„¸ìš”. ì¦ê±°ìš´ í•˜ë£¨ ë³´ë‚´ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# LangChain ë° Upstage ê´€ë ¨ ëª¨ë“ˆ\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# LangGraph ê´€ë ¨ ëª¨ë“ˆ\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- 1. ì´ˆê¸° ì„¤ì • (LLM, Embeddings, Vector DB ë¡œë“œ) ---\n",
    "print(\">>> 1ë‹¨ê³„: ì´ˆê¸° ì„¤ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "load_dotenv()\n",
    "\n",
    "# LLMì„ ChatUpstageë¡œ ì„¤ì •\n",
    "llm = ChatUpstage(model_name=\"solar-1-mini-chat\", temperature=0)\n",
    "\n",
    "# ğŸ’¥ ì„ë² ë”© ëª¨ë¸ë„ Upstageë¡œ í†µì¼!\n",
    "embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "# ì´ì „ì— ë§Œë“¤ì–´ë‘” FAISS ë²¡í„° DB ë¡œë“œ\n",
    "db_path = \"./db/cafe_db\"\n",
    "if not os.path.exists(db_path):\n",
    "    raise FileNotFoundError(f\"'{db_path}' ê²½ë¡œì— ë²¡í„° DBê°€ ì—†ìŠµë‹ˆë‹¤. ì´ì „ ë¬¸ì œì˜ DB êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "# Upstage ì„ë² ë”©ìœ¼ë¡œ ìƒì„±ëœ DBë¥¼ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# ë§Œì•½ DBê°€ OpenAI ì„ë² ë”©ìœ¼ë¡œ ë§Œë“¤ì–´ì¡Œë‹¤ë©´ DB êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸ë¶€í„° ë‹¤ì‹œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "vectorstore = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "print(\"ì´ˆê¸° ì„¤ì • ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "# --- 2. Graph ìƒíƒœ ì •ì˜ (ìˆ˜ì •ëœ ë¶€ë¶„) ---\n",
    "# add_messages ì™€ Annotated ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ê°„ë‹¨í•œ listë¡œ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class GraphState(TypedDict):\n",
    "    messages: list\n",
    "\n",
    "# --- 3. Graph ë…¸ë“œ(Node) í•¨ìˆ˜ ì •ì˜ (ìˆ˜ì •ëœ ë¶€ë¶„) ---\n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "    route: str = Field(description=\"ì£¼ì–´ì§„ ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ê²½ë¡œ. 'menu', 'price', 'recommend', 'general' ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "def classify_input(state: GraphState):\n",
    "    print(\"\\n[ë…¸ë“œ: classify_input]\")\n",
    "    question = state[\"messages\"][-1].content\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(RouteQuery)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"ì‚¬ìš©ì ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ íŒŒì•…í•˜ì—¬ 'menu', 'price', 'recommend', 'general' ë„¤ ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”.\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    \n",
    "    router_chain = prompt | structured_llm\n",
    "    result = router_chain.invoke({\"question\": question})\n",
    "    \n",
    "    print(f\"'{question}' -> ë¶„ë¥˜: {result.route}\")\n",
    "    \n",
    "    # ğŸ’¥ ìˆ˜ì •: ëŒ€í™” ëª©ë¡ì„ ìˆ˜ë™ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "    # ê¸°ì¡´ ë©”ì‹œì§€ ëª©ë¡ì— ìƒˆ ë©”ì‹œì§€ë¥¼ ì¶”ê°€í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    new_message = AIMessage(content=\"\", additional_kwargs={\"route\": result.route})\n",
    "    return {\"messages\": state[\"messages\"] + [new_message]}\n",
    "\n",
    "# ê° ë…¸ë“œì˜ return ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì—¬ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "def search_menu(state: GraphState):\n",
    "    print(\"\\n[ë…¸ë“œ: search_menu]\")\n",
    "    question = state[\"messages\"][-2].content\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    prompt = ChatPromptTemplate.from_template(\"ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:\\n\\n{context}\\n\\nì§ˆë¬¸: {question}\")\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    response = rag_chain.invoke({\"context\": context, \"question\": question})\n",
    "    \n",
    "    # ğŸ’¥ ìˆ˜ì •: ëŒ€í™” ëª©ë¡ì„ ìˆ˜ë™ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "    new_message = AIMessage(content=response)\n",
    "    return {\"messages\": state[\"messages\"] + [new_message]}\n",
    "\n",
    "def search_price(state: GraphState):\n",
    "    print(\"\\n[ë…¸ë“œ: search_price]\")\n",
    "    question = state[\"messages\"][-2].content\n",
    "    retrieved_docs = vectorstore.similarity_search(\"ë©”ë‰´ ê°€ê²©\", k=5)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    prompt = ChatPromptTemplate.from_template(\"ì•„ë˜ ê°€ê²© ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”:\\n\\n{context}\\n\\nì§ˆë¬¸: {question}\")\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    response = rag_chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "    # ğŸ’¥ ìˆ˜ì •: ëŒ€í™” ëª©ë¡ì„ ìˆ˜ë™ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "    new_message = AIMessage(content=response)\n",
    "    return {\"messages\": state[\"messages\"] + [new_message]}\n",
    "\n",
    "def recommend_menu(state: GraphState):\n",
    "    print(\"\\n[ë…¸ë“œ: recommend_menu]\")\n",
    "    question = state[\"messages\"][-2].content\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    if not retrieved_docs:\n",
    "        retrieved_docs = vectorstore.similarity_search(\"ì¸ê¸° ë©”ë‰´\", k=3)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    prompt = ChatPromptTemplate.from_template(\"ì•„ë˜ ë©”ë‰´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë©”ë‰´ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”:\\n\\n{context}\\n\\nì§ˆë¬¸: {question}\")\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    response = rag_chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "    # ğŸ’¥ ìˆ˜ì •: ëŒ€í™” ëª©ë¡ì„ ìˆ˜ë™ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "    new_message = AIMessage(content=response)\n",
    "    return {\"messages\": state[\"messages\"] + [new_message]}\n",
    "\n",
    "def general_response(state: GraphState):\n",
    "    print(\"\\n[ë…¸ë“œ: general_response]\")\n",
    "    question = state[\"messages\"][-2].content\n",
    "    prompt = ChatPromptTemplate.from_template(\"ë‹¹ì‹ ì€ ì¹´í˜ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ëŒ€í™”ë¥¼ ë‚˜ëˆ ì£¼ì„¸ìš”.\\n\\nì§ˆë¬¸: {question}\")\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke({\"question\": question})\n",
    "\n",
    "    # ğŸ’¥ ìˆ˜ì •: ëŒ€í™” ëª©ë¡ì„ ìˆ˜ë™ìœ¼ë¡œ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "    new_message = AIMessage(content=response)\n",
    "    return {\"messages\": state[\"messages\"] + [new_message]}\n",
    "\n",
    "# --- 4. Graph ìƒì„± ë° ì—£ì§€(Edge) ì—°ê²° ---\n",
    "\n",
    "def decide_next_node(state: GraphState):\n",
    "    route = state[\"messages\"][-1].additional_kwargs.get(\"route\", \"general\")\n",
    "    if route == \"menu\": return \"search_menu\"\n",
    "    elif route == \"price\": return \"search_price\"\n",
    "    elif route == \"recommend\": return \"recommend_menu\"\n",
    "    else: return \"general_response\"\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"classifier\", classify_input)\n",
    "workflow.add_node(\"search_menu\", search_menu)\n",
    "workflow.add_node(\"search_price\", search_price)\n",
    "workflow.add_node(\"recommend_menu\", recommend_menu)\n",
    "workflow.add_node(\"general_response\", general_response)\n",
    "workflow.set_entry_point(\"classifier\")\n",
    "workflow.add_conditional_edges(\"classifier\", decide_next_node, {\n",
    "    \"search_menu\": \"search_menu\", \"search_price\": \"search_price\",\n",
    "    \"recommend_menu\": \"recommend_menu\", \"general_response\": \"general_response\",\n",
    "})\n",
    "workflow.add_edge(\"search_menu\", END)\n",
    "workflow.add_edge(\"search_price\", END)\n",
    "workflow.add_edge(\"recommend_menu\", END)\n",
    "workflow.add_edge(\"general_response\", END)\n",
    "\n",
    "# --- 5. Graph ì»´íŒŒì¼ ë° ì‹¤í–‰ ---\n",
    "app = workflow.compile()\n",
    "\n",
    "# ëŒ€í™” ì‹œì‘\n",
    "while True:\n",
    "    user_input = input(\"USER: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "        break\n",
    "    \n",
    "    response = app.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
    "    print(\"ASSISTANT:\", response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
