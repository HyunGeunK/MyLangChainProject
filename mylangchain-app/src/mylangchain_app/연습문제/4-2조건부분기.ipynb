{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79bfed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 1단계: 초기 설정을 시작합니다...\n",
      "초기 설정 완료!\n",
      "\n",
      "[노드: classify_input]\n",
      "'인기메뉴' -> 분류: menu\n",
      "\n",
      "[노드: search_menu]\n",
      "ASSISTANT: 인기 메뉴로는 다음과 같은 커피들이 있습니다:\n",
      "\n",
      "1. **아메리카노**: ₩4,500\n",
      "   - 원두 본연의 맛을 가장 잘 느낄 수 있는 클래식한 블랙 커피입니다.\n",
      "\n",
      "2. **카페라떼**: ₩5,500\n",
      "   - 대표적인 밀크 커피로 크리미한 질감과 부드러운 맛이 특징입니다.\n",
      "\n",
      "3. **카푸치노**: ₩5,000\n",
      "   - 이탈리아 전통 커피로 진한 커피 맛과 부드러운 우유 거품의 조화가 일품입니다.\n",
      "\n",
      "4. **바닐라 라떼**: ₩6,000\n",
      "   - 카페라떼에 달콤한 바닐라 시럽을 더한 인기 메뉴로, 바닐라의 달콤함과 커피의 쌉싸름함이 조화롭게 어우러집니다.\n",
      "\n",
      "5. **카라멜 마키아토**: ₩6,500\n",
      "   - 스팀 밀크 위에 에스프레소를 부어 만든 후 카라멜 시럽과 휘핑크림으로 마무리한 달콤한 커피입니다.\n",
      "\n",
      "6. **프라푸치노**: ₩7,000\n",
      "   - 에스프레소와 우유, 얼음을 블렌더에 갈아 만든 시원한 음료로, 부드럽고 크리미한 질감이 특징입니다.\n",
      "\n",
      "7. **티라미수**: ₩7,500\n",
      "   - 이탈리아 전통 디저트로 부드럽고 달콤한 맛이 특징입니다.\n",
      "\n",
      "이 메뉴들은 각각의 독특한 맛과 특징을 가지고 있어 많은 사람들에게 사랑받고 있습니다.\n",
      "\n",
      "[노드: classify_input]\n",
      "'아메리카 가격' -> 분류: price\n",
      "\n",
      "[노드: search_price]\n",
      "ASSISTANT: 아메리카노의 가격은 ₩4,500입니다.\n",
      "\n",
      "[노드: classify_input]\n",
      "'끝' -> 분류: general\n",
      "\n",
      "[노드: general_response]\n",
      "ASSISTANT: 안녕하세요! 카페 어시스턴트로서 여러분이 편안하고 즐거운 시간을 보내실 수 있도록 도와드리겠습니다. 어떤 음료를 주문하시겠어요? 커피, 차, 스무디 등 다양한 메뉴가 준비되어 있습니다. 또한, 간식이나 디저트도 함께 추천해 드릴 수 있어요.\n",
      "\n",
      "혹시 카페에서 제공하는 와이파이를 사용하시려면 비밀번호가 필요하신가요? 아니면 다른 도움이 필요하시면 언제든지 말씀해 주세요.\n",
      "\n",
      "끝이라는 단어를 보셨으니, 오늘은 어떤 하루를 보내셨는지 궁금하네요. 좋은 일이 있었나요, 아니면 특별한 계획이 있으신가요? 대화를 통해 서로에 대해 좀 더 알아가는 것도 좋을 것 같아요.\n",
      "\n",
      "[노드: classify_input]\n",
      "'' -> 분류: general\n",
      "\n",
      "[노드: general_response]\n",
      "ASSISTANT: 물론이죠! 저희 카페에 오신 것을 환영합니다. 어떤 음료나 디저트를 찾으시는지 도와드릴까요? 저희는 다양한 커피 메뉴, 차, 수제 주스, 그리고 맛있는 케이크와 페이스트리를 제공하고 있습니다. 특별한 추천을 원하시거나 알레르기나 선호도가 있으시면 언제든지 말씀해주세요. 즐거운 하루 보내세요!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "# LangChain 및 Upstage 관련 모듈\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# LangGraph 관련 모듈\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# --- 1. 초기 설정 (LLM, Embeddings, Vector DB 로드) ---\n",
    "print(\">>> 1단계: 초기 설정을 시작합니다...\")\n",
    "load_dotenv()\n",
    "\n",
    "# LLM을 ChatUpstage로 설정\n",
    "llm = ChatUpstage(model_name=\"solar-1-mini-chat\", temperature=0)\n",
    "\n",
    "# 💥 임베딩 모델도 Upstage로 통일!\n",
    "embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "# 이전에 만들어둔 FAISS 벡터 DB 로드\n",
    "db_path = \"./db/cafe_db\"\n",
    "if not os.path.exists(db_path):\n",
    "    raise FileNotFoundError(f\"'{db_path}' 경로에 벡터 DB가 없습니다. 이전 문제의 DB 구축 스크립트를 먼저 실행해주세요.\")\n",
    "\n",
    "# Upstage 임베딩으로 생성된 DB를 로드해야 합니다.\n",
    "# 만약 DB가 OpenAI 임베딩으로 만들어졌다면 DB 구축 스크립트부터 다시 실행해야 합니다.\n",
    "vectorstore = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "print(\"초기 설정 완료!\")\n",
    "\n",
    "\n",
    "# --- 2. Graph 상태 정의 (수정된 부분) ---\n",
    "# add_messages 와 Annotated 를 사용하지 않고 간단한 list로 정의합니다.\n",
    "class GraphState(TypedDict):\n",
    "    messages: list\n",
    "\n",
    "# --- 3. Graph 노드(Node) 함수 정의 (수정된 부분) ---\n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "    route: str = Field(description=\"주어진 질문에 가장 적합한 경로. 'menu', 'price', 'recommend', 'general' 중 하나여야 합니다.\")\n",
    "\n",
    "def classify_input(state: GraphState):\n",
    "    print(\"\\n[노드: classify_input]\")\n",
    "    question = state[\"messages\"][-1].content\n",
    "    \n",
    "    structured_llm = llm.with_structured_output(RouteQuery)\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"사용자 질문의 의도를 파악하여 'menu', 'price', 'recommend', 'general' 네 가지 중 하나로 분류해주세요.\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ])\n",
    "    \n",
    "    router_chain = prompt | structured_llm\n",
    "    result = router_chain.invoke({\"question\": question})\n",
    "    \n",
    "    print(f\"'{question}' -> 분류: {result.route}\")\n",
    "    \n",
    "    # 💥 수정: 대화 목록을 수동으로 관리합니다.\n",
    "    # 기존 메시지 목록에 새 메시지를 추가하여 반환합니다.\n",
    "    new_message = AIMessage(content=\"\", additional_kwargs={\"route\": result.route})\n",
    "    return {\"messages\": state[\"messages\"] + [new_message]}\n",
    "\n",
    "# 각 노드의 return 부분을 수정하여 메시지 리스트를 직접 업데이트합니다.\n",
    "def search_menu(state: GraphState):\n",
    "    print(\"\\n[노드: search_menu]\")\n",
    "    question = state[\"messages\"][-2].content\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    prompt = ChatPromptTemplate.from_template(\"아래 정보를 바탕으로 질문에 답해주세요:\\n\\n{context}\\n\\n질문: {question}\")\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    response = rag_chain.invoke({\"context\": context, \"question\": question})\n",
    "    \n",
    "    # 💥 수정: 대화 목록을 수동으로 관리합니다.\n",
    "    new_message = AIMessage(content=response)\n",
    "    return {\"messages\": state[\"messages\"] + [new_message]}\n",
    "\n",
    "def search_price(state: GraphState):\n",
    "    print(\"\\n[노드: search_price]\")\n",
    "    question = state[\"messages\"][-2].content\n",
    "    retrieved_docs = vectorstore.similarity_search(\"메뉴 가격\", k=5)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    prompt = ChatPromptTemplate.from_template(\"아래 가격 정보를 바탕으로 질문에 답해주세요:\\n\\n{context}\\n\\n질문: {question}\")\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    response = rag_chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "    # 💥 수정: 대화 목록을 수동으로 관리합니다.\n",
    "    new_message = AIMessage(content=response)\n",
    "    return {\"messages\": state[\"messages\"] + [new_message]}\n",
    "\n",
    "def recommend_menu(state: GraphState):\n",
    "    print(\"\\n[노드: recommend_menu]\")\n",
    "    question = state[\"messages\"][-2].content\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    if not retrieved_docs:\n",
    "        retrieved_docs = vectorstore.similarity_search(\"인기 메뉴\", k=3)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    prompt = ChatPromptTemplate.from_template(\"아래 메뉴 정보를 바탕으로 메뉴를 추천해주세요:\\n\\n{context}\\n\\n질문: {question}\")\n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    response = rag_chain.invoke({\"context\": context, \"question\": question})\n",
    "\n",
    "    # 💥 수정: 대화 목록을 수동으로 관리합니다.\n",
    "    new_message = AIMessage(content=response)\n",
    "    return {\"messages\": state[\"messages\"] + [new_message]}\n",
    "\n",
    "def general_response(state: GraphState):\n",
    "    print(\"\\n[노드: general_response]\")\n",
    "    question = state[\"messages\"][-2].content\n",
    "    prompt = ChatPromptTemplate.from_template(\"당신은 카페 어시스턴트입니다. 일반적인 대화를 나눠주세요.\\n\\n질문: {question}\")\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke({\"question\": question})\n",
    "\n",
    "    # 💥 수정: 대화 목록을 수동으로 관리합니다.\n",
    "    new_message = AIMessage(content=response)\n",
    "    return {\"messages\": state[\"messages\"] + [new_message]}\n",
    "\n",
    "# --- 4. Graph 생성 및 엣지(Edge) 연결 ---\n",
    "\n",
    "def decide_next_node(state: GraphState):\n",
    "    route = state[\"messages\"][-1].additional_kwargs.get(\"route\", \"general\")\n",
    "    if route == \"menu\": return \"search_menu\"\n",
    "    elif route == \"price\": return \"search_price\"\n",
    "    elif route == \"recommend\": return \"recommend_menu\"\n",
    "    else: return \"general_response\"\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"classifier\", classify_input)\n",
    "workflow.add_node(\"search_menu\", search_menu)\n",
    "workflow.add_node(\"search_price\", search_price)\n",
    "workflow.add_node(\"recommend_menu\", recommend_menu)\n",
    "workflow.add_node(\"general_response\", general_response)\n",
    "workflow.set_entry_point(\"classifier\")\n",
    "workflow.add_conditional_edges(\"classifier\", decide_next_node, {\n",
    "    \"search_menu\": \"search_menu\", \"search_price\": \"search_price\",\n",
    "    \"recommend_menu\": \"recommend_menu\", \"general_response\": \"general_response\",\n",
    "})\n",
    "workflow.add_edge(\"search_menu\", END)\n",
    "workflow.add_edge(\"search_price\", END)\n",
    "workflow.add_edge(\"recommend_menu\", END)\n",
    "workflow.add_edge(\"general_response\", END)\n",
    "\n",
    "# --- 5. Graph 컴파일 및 실행 ---\n",
    "app = workflow.compile()\n",
    "\n",
    "# 대화 시작\n",
    "while True:\n",
    "    user_input = input(\"USER: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\"]:\n",
    "        break\n",
    "    \n",
    "    response = app.invoke({\"messages\": [HumanMessage(content=user_input)]})\n",
    "    print(\"ASSISTANT:\", response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
