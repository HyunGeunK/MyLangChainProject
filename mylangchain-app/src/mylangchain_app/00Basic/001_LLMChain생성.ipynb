{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3024310296.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpoetry add python-dotenv langchain langchain-openai\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_Y\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능 모델의 학습 원리는 다음과 같습니다.\\n\\n1.  **데이터 수집**: 인공지능 모델은 대량의 데이터를 수집합니다. 이 데이터는 모델이 학습하는 데 필요한 정보입니다.\\n2.  **데이터 전처리**: 수집된 데이터를 전처리합니다. 데이터를 정리하고, 변환하여 모델이 학습하기 쉽게 만드는 과정입니다.\\n3.  **모델 초기화**: 인공지능 모델을 초기화합니다. 모델의 가중치와 편향은 무작위로 설정됩니다.\\n4.  **학습**: 모델은 수집된 데이터를 사용하여 학습합니다. 모델은 데이터의 패턴을 인식하고, 예측합니다.\\n5.  **오류 계산**: 모델의 예측과 실제 값 사이의 오류를 계산합니다. 이 오류는 모델의 성능을 평가하는 데 사용됩니다.\\n6.  **가중치 업데이트**: 모델의 가중치와 편향을 업데이트합니다. 이 과정은 오류를 최소화하기 위해 수행됩니다. \\n7.  **반복**: 위의 과정을 반복합니다. 모델은 데이터를 학습하고, 오류를 최소화하며, 가중치를 업데이트합니다.\\n\\n인공지능 모델의 학습 원리는 반복적인 과정입니다. 모델은 데이터를 학습하고, 오류를 최소화하며, 가중치를 업데이트합니다. 이 과정을 통해 모델은 점점 더 정확해집니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 258, 'prompt_tokens': 24, 'total_tokens': 282, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.204637732, 'prompt_time': 0.000192717, 'completion_time': 0.589433312, 'total_time': 0.589626029}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'id': 'chatcmpl-28260d8c-2539-4e7c-a9bf-8c3a3987bf04', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--4548563b-12b8-45fb-9209-f593e60239cb-0' usage_metadata={'input_tokens': 24, 'output_tokens': 258, 'total_tokens': 282, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "1.  **데이터 수집**: 인공지능 모델은 대량의 데이터를 수집합니다. 이 데이터는 모델이 학습하는 데 필요한 정보입니다.\n",
      "2.  **데이터 전처리**: 수집된 데이터를 전처리합니다. 데이터를 정리하고, 변환하여 모델이 학습하기 쉽게 만드는 과정입니다.\n",
      "3.  **모델 초기화**: 인공지능 모델을 초기화합니다. 모델의 가중치와 편향은 무작위로 설정됩니다.\n",
      "4.  **학습**: 모델은 수집된 데이터를 사용하여 학습합니다. 모델은 데이터의 패턴을 인식하고, 예측합니다.\n",
      "5.  **오류 계산**: 모델의 예측과 실제 값 사이의 오류를 계산합니다. 이 오류는 모델의 성능을 평가하는 데 사용됩니다.\n",
      "6.  **가중치 업데이트**: 모델의 가중치와 편향을 업데이트합니다. 이 과정은 오류를 최소화하기 위해 수행됩니다. \n",
      "7.  **반복**: 위의 과정을 반복합니다. 모델은 데이터를 학습하고, 오류를 최소화하며, 가중치를 업데이트합니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 반복적인 과정입니다. 모델은 데이터를 학습하고, 오류를 최소화하며, 가중치를 업데이트합니다. 이 과정을 통해 모델은 점점 더 정확해집니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content=\"인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것입니다.\\n\\n예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 모델에 고양이와 강아지의 사진을 많이 보여주면서 '이것은 고양이야', '이것은 강아지야'라고 알려주면, 모델은 이 사진들의 특징을 분석하기 시작합니다.\\n\\n고양이 사진에는 고양이의 특징인 귀가 있고, 강아지 사진에는 강아지 귀가 있습니다. 모델은 이 특징들을 학습하면서 고양이와 강아지를 구분하는 기준을 만듭니다.\\n\\n이렇게 모델이 학습하는 과정을 수식으로 나타내면, 다음과 같습니다.\\n\\n1. **데이터 수집**: 많은 양의 데이터(고양이와 강아지의 사진)를 수집합니다.\\n2. **데이터 전처리**: 데이터를 컴퓨터가 처리할 수 있는 형태로 변환합니다.\\n3. **모델 정의**: 모델의 구조를 정의합니다. (예: 신경망)\\n4. **손실 함수 정의**: 모델의 성능을 평가하는 손실 함수를 정의합니다. (예: 크로스 엔트로피)\\n5. **최적화 알고리즘 선택**: 모델의 가중치를 업데이트하는 최적화 알고리즘을 선택합니다. (예: 경사 하강법)\\n6. **학습**: 모델을 학습합니다. (예: 고양이/강아지 분류)\\n\\n학습 과정에서는 모델의 가중치를 업데이트하면서 손실 함수를 최소화하는 방향으로 학습합니다. 이렇게 학습한 모델은 새로운 사진을 보여주었을 때, 고양이인지 강아지인지 분류할 수 있습니다.\\n\\n이러한 학습 원리는 다양한 인공지능 모델에 적용할 수 있으며, 모델의 성능을 높이는데 중요한 역할을 합니다.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 365, 'prompt_tokens': 36, 'total_tokens': 401, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.204232015, 'prompt_time': 0.000520512, 'completion_time': 0.85538572, 'total_time': 0.855906232}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'id': 'chatcmpl-ba7fbc78-b857-4609-8009-83b36754ed67', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--40b89a02-91a2-4524-9efe-1b94d6fbb75c-0' usage_metadata={'input_tokens': 36, 'output_tokens': 365, 'total_tokens': 401, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "170ec878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것입니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 모델에 고양이와 강아지의 사진을 많이 보여주면서 '이것은 고양이야', '이것은 강아지야'라고 알려주면, 모델은 이 사진들의 특징을 분석하기 시작합니다.\n",
      "\n",
      "고양이 사진에는 고양이의 특징인 귀가 있고, 강아지 사진에는 강아지 귀가 있습니다. 모델은 이 특징들을 학습하면서 고양이와 강아지를 구분하는 기준을 만듭니다.\n",
      "\n",
      "이렇게 모델이 학습하는 과정을 수식으로 나타내면, 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 많은 양의 데이터(고양이와 강아지의 사진)를 수집합니다.\n",
      "2. **데이터 전처리**: 데이터를 컴퓨터가 처리할 수 있는 형태로 변환합니다.\n",
      "3. **모델 정의**: 모델의 구조를 정의합니다. (예: 신경망)\n",
      "4. **손실 함수 정의**: 모델의 성능을 평가하는 손실 함수를 정의합니다. (예: 크로스 엔트로피)\n",
      "5. **최적화 알고리즘 선택**: 모델의 가중치를 업데이트하는 최적화 알고리즘을 선택합니다. (예: 경사 하강법)\n",
      "6. **학습**: 모델을 학습합니다. (예: 고양이/강아지 분류)\n",
      "\n",
      "학습 과정에서는 모델의 가중치를 업데이트하면서 손실 함수를 최소화하는 방향으로 학습합니다. 이렇게 학습한 모델은 새로운 사진을 보여주었을 때, 고양이인지 강아지인지 분류할 수 있습니다.\n",
      "\n",
      "이러한 학습 원리는 다양한 인공지능 모델에 적용할 수 있으며, 모델의 성능을 높이는데 중요한 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 사람의 뇌는 경험을 통해 학습하고, 이를 통해 새로운 상황에 대처할 수 있습니다. 인공지능 모델도 데이터를 통해 학습하고, 이를 통해 새로운 입력에 대한 출력을 예측할 수 있습니다.\n",
      "\n",
      "구체적으로 설명하면, 인공지능 모델의 학습 과정은 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해서는大量的한 데이터가 필요합니다. 이 데이터는 문제에 대한 입력과 출력으로 구성됩니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터는 모델에 입력되기 전에 전처리 과정을 거칩니다. 이 과정에서는 데이터의 품질을 높이고, 데이터의 크기를 줄이는 등의 작업이 수행됩니다.\n",
      "\n",
      "3. **모델 선택**: 인공지능 모델에는 여러 가지 유형이 있습니다. 문제의 성격에 따라 적합한 모델을 선택해야 합니다.\n",
      "\n",
      "4. **학습**: 선택된 모델에 전처리된 데이터를 입력하여 학습을 시작합니다. 이 과정에서 모델은 데이터의 패턴을 학습하고, 입력과 출력 사이의 관계를 발견하려고 합니다.\n",
      "\n",
      "5. **평가**: 학습이 완료된 후, 모델의 성능을 평가합니다. 이를 통해 모델의 정확도를 측정하고, 추가적인 조정이 필요한지 결정할 수 있습니다.\n",
      "\n",
      "6. **튜닝**: 모델의 성능이 만족스럽지 않은 경우, 모델의 하이퍼파рамет수를 조정하거나, 학습 데이터를 추가하는 등의 방법을 통해 모델을 개선할 수 있습니다.\n",
      "\n",
      "예를 들어, 이미지 분류 모델을 학습시키는 경우, 고양이와 강아지의 사진을大量的으로 수집하고, 이를 통해 모델이 고양이와 강아지를 구별할 수 있도록 학습시킵니다. 학습이 완료된 후, 새로운 이미지를 입력하면 모델은 이를 고양이 또는 강아지로 분류할 수 있습니다.\n",
      "\n",
      "이러한 학습 원리는 다양한 인공지능 모델에 적용될 수 있으며, 이를 통해 모델은 복잡한 문제를 해결할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것이죠.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다.\n",
      "\n",
      "1. **데이터 수집**: 수많은 고양이와 강아지의 사진을 수집합니다.\n",
      "2. **데이터 준비**: 수집한 사진을 컴퓨터가 이해할 수 있는 형태로 변환합니다.\n",
      "3. **모델 초기화**: 모델을 처음부터 생성합니다. 이 모델은 고양이와 강아지 사진을 구분할 수 있는 능력이 없습니다.\n",
      "4. **학습**: 모델에 고양이 사진과 강아지 사진을 보여주고, \"이것은 고양이입니다\" 또는 \"이것은 강아지입니다\"와 같은 라벨을 제공합니다. 모델은 이 데이터를 통해 고양이와 강아지의 특징을 스스로 학습합니다.\n",
      "5. **예측**: 모델에 새로운 사진을 보여주면, 모델은 학습한 내용을 바탕으로 \"이것은 고양이입니다\" 또는 \"이것은 강아지입니다\"라고 예측합니다.\n",
      "\n",
      "모델이 학습하는 과정은 다음과 같습니다.\n",
      "\n",
      "* **패턴 인식**: 모델은 데이터에서 패턴을 인식합니다. 예를 들어, 고양이 사진에는 고양이의 눈, 코, 귀 등이 있고, 강아지 사진에는 강아지의 눈, 코, 귀 등이 있습니다.\n",
      "* **가중치 업데이트**: 모델은 패턴을 인식하고, 예측 결과와 실제 라벨 간의 차이를 계산합니다. 이 차이 값을 바탕으로 모델은 스스로 가중치를 업데이트합니다.\n",
      "* **반복 학습**: 모델은 데이터를 반복적으로 학습하면서 가중치를 업데이트하고, 예측 정확도를 높입니다.\n",
      "\n",
      "이와 같은 학습 과정을 통해 인공지능 모델은 데이터를 통해 스스로 학습하고, 새로운 데이터에 대해 예측할 수 있는 능력을 갖추게 됩니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "**영화:** '뷰티풀 마인드'(2001)\n",
      "\n",
      "**감독:** 론 하워드\n",
      "\n",
      "**주연:** 러셀 크로우, 제니퍼 콘넬리, 조쉬 루카스\n",
      "\n",
      "**줄거리:** 이 영화는 미국의 수학자 존 내시(John Nash)의 실화를 바탕으로 한 드라마입니다. 존 내시는 프린스턴 대학에서 수학을 전공하며 탁월한 재능을 보여줍니다. 하지만 그는 조현병이라는 정신질환을 앓고 있으며, 이로 인해 현실과 환상을 구분하지 못하게 됩니다.\n",
      "\n",
      "영화는 존 내시의 삶과 투쟁을 감동적으로 그려냅니다. 그는 수학에서 뛰어난 성과를 거두지만, 조현병으로 인해 고통을 받습니다. 영화는 그의 아내 리시아(Licia)와 그의 동료들의 지지를 통해 그가 조현병을 극복하고 수학에 복귀하는 과정을 보여줍니다.\n",
      "\n",
      "**추천 이유:**\n",
      "\n",
      "*   감동적인 이야기: 이 영화는 존 내시의 삶과 투쟁을 감동적으로 그려냅니다.\n",
      "*   우수한 연기: 러셀 크로우와 제니퍼 콘넬리의 연기는 매우 인상적입니다.\n",
      "*   역사적 가치: 이 영화는 존 내시의 실화를 바탕으로 하며, 그의 삶과 업적을 소개합니다.\n",
      "\n",
      "이 영화는 드라마 장르에서 추천할 만한 영화입니다. 감동적인 이야기, 우수한 연기, 역사적 가치로 인해 많은 사람들에게 추천할 만합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000022D13D9A3F0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022D13D9BAD0>, root_client=<openai.OpenAI object at 0x0000022D13BF51C0>, root_async_client=<openai.AsyncOpenAI object at 0x0000022D13D9A360>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000022D13D9A3F0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000022D13D9BAD0>, root_client=<openai.OpenAI object at 0x0000022D13BF51C0>, root_async_client=<openai.AsyncOpenAI object at 0x0000022D13D9A360>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " **노트북 (The Notebook, 2004)**\n",
      "\n",
      "*   **제목:** 노트북 (The Notebook, 2004)\n",
      "*   **감독:** 닉 카사베테스\n",
      "*   **출연:** 라이언 고슬링, 레이철 맥아담스\n",
      "\n",
      "사랑과 기억, 삶의 진정한 의미를 감동적으로 전달하는 영화입니다. 노아와 앨리라는 두 주인공이 서로에 대한 사랑을 키워가는 과정을 통해 시간과 공간을 초월한 진정한 사랑의 가치를 보여줍니다.\n",
      "\n",
      "이 영화는 아름다운 영상미와 감동적인 연기로 많은 이들에게 사랑받고 있습니다. 로맨틱한 장면들과 감동적인 결말이 돋보이며, 사랑과 희생, 그리고 영원한 사랑에 대한 메시지를 전달합니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e30883ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('## 영화 제목: <원더>\\n'\n",
      " '\\n'\n",
      " '감독: 스티븐 쇼보스키 \\n'\n",
      " '\\n'\n",
      " '출연진: 제이콥 트렘블레이, 오웬 윌슨, 줄리아 로버츠, 밋치 매코넬 \\n'\n",
      " '\\n'\n",
      " '어느 소년이 얼굴에 큰 반점이 있는 채로 태어납니다. 이 소년은 가족과 함께 학교에 처음 입학하게 되는데, 그곳에서 많은 사람들에게 '\n",
      " '괴롭힘을 당하게 됩니다. 그럼에도 불구하고 소년은 용기 내어 사람들에게 다가가고, 그들과 소통하려고 노력합니다.\\n'\n",
      " '\\n'\n",
      " '장르: 드라마, 가족 \\n'\n",
      " '\\n'\n",
      " '국가: 미국 \\n'\n",
      " '\\n'\n",
      " '개봉일: 2017년 12월 20일')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
