{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0fa4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8264ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIza\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(GOOGLE_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93f00ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google Gemini Response:\n",
      "LangChain은 대규모 언어 모델(LLM)을 애플리케이션에 통합하기 위한 프레임워크입니다.  단순히 LLM을 호출하는 것 이상으로, 여러 LLM을 연결하고, 외부 데이터 소스와 상호 작용하며, 메모리 및 체인을 사용하여 복잡한 작업을 수행할 수 있도록 설계되었습니다.  핵심 기능은 다음과 같습니다.\n",
      "\n",
      "* **모듈성:** LangChain은 다양한 LLM, 프로세서, 메모리, 데이터 연결 등을 모듈화하여 사용자가 필요에 따라 구성할 수 있도록 합니다.  이는 특정 LLM에 종속되지 않고 다양한 모델을 쉽게 교체할 수 있다는 것을 의미합니다.\n",
      "\n",
      "* **체인(Chains):** 여러 구성 요소를 순차적으로 또는 병렬적으로 연결하여 복잡한 작업을 수행할 수 있습니다. 예를 들어, 문서를 요약하고, 요약 내용을 기반으로 질문에 답하는 체인을 만들 수 있습니다.\n",
      "\n",
      "* **인덱싱 및 검색:** 외부 데이터 소스(문서, 데이터베이스 등)를 인덱싱하고 검색하여 LLM이 외부 정보를 활용할 수 있도록 합니다.  이는 LLM의 지식 범위를 확장하고, 최신 정보를 활용하는 애플리케이션을 구축하는 데 필수적입니다.\n",
      "\n",
      "* **메모리:** LLM과의 이전 상호 작용을 기억하여 컨텍스트를 유지하고, 더욱 자연스럽고 일관성 있는 대화를 가능하게 합니다.  다양한 메모리 유형을 제공하여 애플리케이션의 요구 사항에 맞게 선택할 수 있습니다.\n",
      "\n",
      "* **에이전트(Agents):** LLM이 외부 도구(검색 엔진, 계산기 등)를 사용하여 작업을 수행할 수 있도록 합니다.  LLM은 어떤 도구를 사용할지 결정하고, 도구의 결과를 활용하여 최종 결과를 생성합니다.\n",
      "\n",
      "**LangChain의 장점:**\n",
      "\n",
      "* **개발 속도 향상:** 모듈식 설계와 다양한 기능을 통해 LLM 기반 애플리케이션 개발 시간을 단축할 수 있습니다.\n",
      "* **유연성:** 다양한 LLM, 데이터 소스, 구성 요소를 지원하여 다양한 애플리케이션에 적용 가능합니다.\n",
      "* **확장성:** 모듈식 설계 덕분에 애플리케이션을 쉽게 확장할 수 있습니다.\n",
      "* **재사용성:** 구성 요소를 재사용하여 새로운 애플리케이션을 빠르게 개발할 수 있습니다.\n",
      "\n",
      "\n",
      "**LangChain의 활용 예시:**\n",
      "\n",
      "* **챗봇:**  외부 데이터베이스를 검색하여 질문에 답하는 챗봇 개발\n",
      "* **요약 도구:**  긴 문서를 요약하고, 요약 내용을 기반으로 질문에 답하는 도구 개발\n",
      "* **코드 생성:**  자연어 설명을 기반으로 코드를 생성하는 도구 개발\n",
      "* **데이터 분석:**  데이터를 분석하고, 결과를 자연어로 요약하는 도구 개발\n",
      "\n",
      "\n",
      "LangChain은 LLM을 활용한 애플리케이션 개발을 위한 강력한 도구이며,  LLM의 기능을 극대화하고, 다양한 애플리케이션을 구축하는 데 유용합니다.  하지만 LLM 자체의 한계(환각, 편향 등)를 인지하고, 이를 완화하기 위한 노력이 필요합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",  # 또는 \"gemini-pro-vision\"\n",
    "    temperature=0.3    \n",
    ")\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 AI 전문가입니다.\"),\n",
    "    (\"human\", \"{topic}은 무엇인가요?\")\n",
    "])\n",
    "\n",
    "# 체인 실행\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"topic\": \"LangChain\"})\n",
    "\n",
    "print(\" Google Gemini Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bcfff",
   "metadata": {},
   "source": [
    "#### Gemini 모델별 특징\n",
    "\n",
    "* gemini-1.5-flash: 빠른 응답, 일반적인 작업에 적합\n",
    "* gemini-1.5-pro: 더 정확하고 복잡한 추론 작업\n",
    "* gemini-pro-vision: 이미지 처리 및 멀티모달 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37613cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "예제 1: 기본 대화형 챗봇\n",
      "==================================================\n",
      "응답: 파이썬에서 리스트를 정렬하는 방법은 여러 가지가 있습니다.  어떤 방법을 사용할지는 리스트의 내용과 정렬 기준에 따라 달라집니다.  자세히 알아보겠습니다.\n",
      "\n",
      "**1. `list.sort()` 메서드:**\n",
      "\n",
      "* **리스트 자체를 변경합니다.**  새로운 리스트를 반환하지 않고 원본 리스트를 직접 정렬합니다.\n",
      "* **반환값은 `None`입니다.**\n",
      "* **`key` 인자:**  정렬 기준을 지정할 수 있습니다.  `key` 인자에는 정렬 기준을 정의하는 함수를 넣습니다.  예를 들어, 문자열 리스트를 길이 순으로 정렬하려면 `key=len`을 사용합니다.\n",
      "* **`reverse` 인자:**  내림차순 정렬을 원할 경우 `reverse=True`를 사용합니다.\n",
      "\n",
      "\n",
      "```python\n",
      "my_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "\n",
      "# 오름차순 정렬 (기본값)\n",
      "my_list.sort()\n",
      "print(f\"오름차순 정렬: {my_list}\")  # 출력: 오름차순 정렬: [1, 1, 2, 3, 4, 5, 6, 9]\n",
      "\n",
      "# 내림차순 정렬\n",
      "my_list.sort(reverse=True)\n",
      "print(f\"내림차순 정렬: {my_list}\")  # 출력: 내림차순 정렬: [9, 6, 5, 4, 3, 2, 1, 1]\n",
      "\n",
      "\n",
      "words = [\"banana\", \"apple\", \"kiwi\", \"orange\"]\n",
      "\n",
      "# 길이 순으로 정렬\n",
      "words.sort(key=len)\n",
      "print(f\"길이 순 정렬: {words}\")  # 출력: 길이 순 정렬: ['kiwi', 'apple', 'banana', 'orange']\n",
      "\n",
      "\n",
      "# 객체 리스트 정렬 (객체의 특정 속성 기준)\n",
      "class Person:\n",
      "    def __init__(self, name, age):\n",
      "        self.name = name\n",
      "        self.age = age\n",
      "\n",
      "people = [Person(\"Alice\", 30), Person(\"Bob\", 25), Person(\"Charlie\", 35)]\n",
      "people.sort(key=lambda person: person.age) # age 속성으로 정렬\n",
      "print(f\"나이 순 정렬: {[person.name for person in people]}\") # 출력: 나이 순 정렬: ['Bob', 'Alice', 'Charlie']\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "**2. `sorted()` 함수:**\n",
      "\n",
      "* **새로운 리스트를 반환합니다.** 원본 리스트는 변경되지 않습니다.\n",
      "* **`key` 인자와 `reverse` 인자를 `list.sort()`와 동일하게 사용합니다.**\n",
      "\n",
      "\n",
      "```python\n",
      "my_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "\n",
      "# 오름차순 정렬\n",
      "sorted_list = sorted(my_list)\n",
      "print(f\"오름차순 정렬 (sorted 함수): {sorted_list}\")  # 출력: 오름차순 정렬 (sorted 함수): [1, 1, 2, 3, 4, 5, 6, 9]\n",
      "print(f\"원본 리스트: {my_list}\")  # 출력: 원본 리스트: [3, 1, 4, 1, 5, 9, 2, 6] (변경되지 않음)\n",
      "\n",
      "# 내림차순 정렬\n",
      "sorted_list = sorted(my_list, reverse=True)\n",
      "print(f\"내림차순 정렬 (sorted 함수): {sorted_list}\") # 출력: 내림차순 정렬 (sorted 함수): [9, 6, 5, 4, 3, 2, 1, 1]\n",
      "\n",
      "```\n",
      "\n",
      "\n",
      "어떤 방법을 사용할지는 상황에 따라 선택하면 됩니다.  원본 리스트를 변경하고 싶지 않다면 `sorted()` 함수를, 원본 리스트를 직접 변경하고 메모리를 절약하고 싶다면 `list.sort()` 메서드를 사용하는 것이 효율적입니다.  `key` 인자를 활용하여 다양한 정렬 기준을 적용할 수 있다는 점을 기억하세요.\n",
      "\n",
      "==================================================\n",
      "예제 2: JSON 구조화 출력\n",
      "==================================================\n",
      "JSON 결과: ```json\n",
      "{\"name\": \"네이버\", \"year\": \"1999\", \"location\": \"경기도 성남\"}\n",
      "```\n",
      "\n",
      "==================================================\n",
      "예제 3: 번역 체인\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 기본 모델 설정\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"예제 1: 기본 대화형 챗봇\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 대화형 프롬프트\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친근하고 도움이 되는 AI 어시스턴트입니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "chat_chain = chat_prompt | llm | StrOutputParser()\n",
    "response1 = chat_chain.invoke({\"user_input\": \"파이썬으로 리스트를 정렬하는 방법은?\"})\n",
    "print(\"응답:\", response1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 2: JSON 구조화 출력\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "다음 정보를 JSON 형태로 변환하세요:\n",
    "{company_info}\n",
    "\n",
    "형식: {{\"name\": \"회사명\", \"year\": \"연도\", \"location\": \"위치\"}}\n",
    "\"\"\",\n",
    "    input_variables=[\"company_info\"]\n",
    ")\n",
    "\n",
    "json_chain = json_prompt | llm | StrOutputParser()\n",
    "company_text = \"네이버는 1999년에 설립된 한국의 IT 기업이며 본사는 경기도 성남에 있습니다.\"\n",
    "response2 = json_chain.invoke({\"company_info\": company_text})\n",
    "print(\"JSON 결과:\", response2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 3: 번역 체인\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"다음 텍스트를 {target_language}로 번역하세요: {text}\"\n",
    ")\n",
    "\n",
    "translate_chain = translate_prompt | llm | StrOutputParser()\n",
    "original = \"Hello, how are you today?\"\n",
    "translated = translate_chain.invoke({\n",
    "    \"text\": original, \n",
    "    \"target_language\": \"한국어\"\n",
    "})\n",
    "print(\"번역 결과:\", translated)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 4: 감정 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "emotion_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "텍스트: {text}\n",
    "감정을 분석하고 [긍정/부정/중립]과 1-10점수를 매기세요.\n",
    "\"\"\")\n",
    "\n",
    "emotion_chain = emotion_prompt | llm | StrOutputParser()\n",
    "test_text = \"오늘 프로젝트가 성공적으로 완료되어서 정말 기쁩니다!\"\n",
    "emotion_result = emotion_chain.invoke({\"text\": test_text})\n",
    "print(\"감정 분석:\", emotion_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 5: 코드 생성\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "code_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "{language}로 {task} 기능을 구현하는 간단한 코드를 작성하세요.\n",
    "\"\"\")\n",
    "\n",
    "code_chain = code_prompt | llm | StrOutputParser()\n",
    "code_result = code_chain.invoke({\n",
    "    \"language\": \"Python\",\n",
    "    \"task\": \"두 숫자의 최대공약수를 구하는\"\n",
    "})\n",
    "print(\"생성된 코드:\")\n",
    "print(code_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 6: 창의적 콘텐츠 생성\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "001da18f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StrOutputParser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      2\u001b[39m llm_creative = ChatGoogleGenerativeAI(\n\u001b[32m      3\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgemini-1.5-flash\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m     temperature=\u001b[32m0.9\u001b[39m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m creative_prompt = ChatPromptTemplate.from_template(\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{topic}\u001b[39;00m\u001b[33m에 대한 창의적인 \u001b[39m\u001b[38;5;132;01m{content_type}\u001b[39;00m\u001b[33m를 \u001b[39m\u001b[38;5;132;01m{style}\u001b[39;00m\u001b[33m 스타일로 작성하세요.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m creative_chain = creative_prompt | llm_creative | \u001b[43mStrOutputParser\u001b[49m()\n\u001b[32m     12\u001b[39m creative_result = creative_chain.invoke({\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m미래의 교통수단\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcontent_type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m아이디어\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstyle\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m혁신적이고 실현 가능한\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m })\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m창의적 아이디어:\u001b[39m\u001b[33m\"\u001b[39m, creative_result)\n",
      "\u001b[31mNameError\u001b[39m: name 'StrOutputParser' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# 창의적 생성용 높은 temperature\n",
    "llm_creative = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "creative_prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}에 대한 창의적인 {content_type}를 {style} 스타일로 작성하세요.\"\n",
    ")\n",
    "\n",
    "creative_chain = creative_prompt | llm_creative | StrOutputParser()\n",
    "creative_result = creative_chain.invoke({\n",
    "    \"topic\": \"미래의 교통수단\",\n",
    "    \"content_type\": \"아이디어\",\n",
    "    \"style\": \"혁신적이고 실현 가능한\"\n",
    "})\n",
    "print(\"창의적 아이디어:\", creative_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Gemini 모델 옵션\")\n",
    "print(\"=\" * 50)\n",
    "print(\"• gemini-1.5-flash: 빠른 응답, 일반 작업\")\n",
    "print(\"• gemini-1.5-pro: 정확한 분석, 복잡한 추론\")\n",
    "print(\"• gemini-pro-vision: 이미지 처리 가능\")\n",
    "print(\"• temperature: 0.1(정확) ~ 0.9(창의적)\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
