{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add pypdf=\">=4.2.0,<5.0.0\"\n",
    "# poetry add langchain-upstage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 환경변수 불러오기\n",
    "\n",
    "- `.env` 파일에 `UPSTAGE_API_KEY` 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up_X\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LLM 답변 생성\n",
    "\n",
    "- Upstage Console에서 발급받은 API Key를 `UPSTAGE_API_KEY`라고 저장하면 별도의 설정 없이 `ChatUpstage`를 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "#llm = ChatUpstage(temperature=0.5)\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "**LangChain**은 대규모 언어 모델(LLM, Large Language Model)을 활용해 애플리케이션 개발을 용이하게 하는 **오픈소스 프레임워크**입니다. LLM의 강력한 기능을 실제 서비스에 통합할 때 발생하는 복잡성(예: 컨텍스트 관리, 도구 연동, 메모리 처리 등)을 해결하기 위해 설계되었습니다.\n",
      "\n",
      "### 📌 **LangChain의 핵심 개념**\n",
      "1. **모듈식 설계**  \n",
      "   - LLM, 프롬프트, 메모리, 검색, 체인(Chain), 에이전트(Agent) 등을 조합해 유연하게 시스템을 구축할 수 있습니다.\n",
      "   - 예: `Prompt Template + LLM + Retrieval`을 연결해 QA 시스템 생성.\n",
      "\n",
      "2. **주요 구성 요소**  \n",
      "   - **모델 I/O**: OpenAI, Anthropic, HuggingFace 등 다양한 LLM과 호환.\n",
      "   - **체인(Chain)**: 여러 컴포넌트를 연결해 복잡한 작업 처리 (예: 요약 → 번역 → 저장).\n",
      "   - **에이전트(Agent)**: LLM이 동적으로 도구를 선택해 작업 수행 (예: 계산기, 검색 엔진 호출).\n",
      "   - **메모리(Memory)**: 대화 기록을 유지해 컨텍스트 지속 (챗봇에 유용).\n",
      "   - **데이터 연결**: 벡터 DB(Pinecone, FAISS), API, SQL 등과 연동.\n",
      "\n",
      "3. **사용 사례**  \n",
      "   - **챗봇**: 대화 기록과 외부 지식 검색 결합.\n",
      "   - **자동화된 문서 처리**: PDF 분석 → 요약 → 데이터베이스 저장.\n",
      "   - **코드 생성**: GitHub API와 연동해 코드 추천.\n",
      "\n",
      "### 🛠 **LangChain의 장점**\n",
      "- **생산성 향상**: 복잡한 파이프라인을 코드로 간단히 구현.\n",
      "- **확장성**: 커스텀 모듈 추가 가능 (예: 자체 LLM 통합).\n",
      "- **커뮤니티 지원**: 활발한 생태계로 튜토리얼과 예제 풍부.\n",
      "\n",
      "### 📦 **기술 스택 예시**\n",
      "```python\n",
      "from langchain.chains import RetrievalQA\n",
      "from langchain.llms import OpenAI\n",
      "from langchain.vectorstores import Chroma\n",
      "from langchain.embeddings import OpenAIEmbeddings\n",
      "\n",
      "# 1. 벡터 DB 로드\n",
      "embedding = OpenAIEmbeddings()\n",
      "db = Chroma(persist_directory='./docs', embedding_function=embedding)\n",
      "\n",
      "# 2. LLM + 검색 체인 생성\n",
      "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=db.as_retriever())\n",
      "\n",
      "# 3. 질문 응답\n",
      "result = qa.run(\"2023년 매출은 얼마인가요?\")\n",
      "print(result)\n",
      "```\n",
      "\n",
      "### 🔍 **참고 자료**\n",
      "- 공식 문서: [https://python.langchain.com](https://python.langchain.com)\n",
      "- GitHub: [https://github.com/langchain-ai/langchain](https://github.com/langchain-ai/langchain)\n",
      "\n",
      "LangChain은 LLM 기반 애플리케이션 개발을 **\"레고 조립\"** 하듯이 쉽게 만들어주는 도구로, 특히 복잡한 워크플로우가 필요한 경우 유용합니다.\n"
     ]
    }
   ],
   "source": [
    "ai_message=llm.invoke(\"LangChain은 무엇인가요?\")\n",
    "print(type(ai_message))\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using chat stream\n",
    "for chunk in llm.stream(\"LangChain은 무엇인가요?\"):\n",
    "    print(chunk.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "translation_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a professional translator specializing in Korean-English translation.\"),\n",
    "        (\"human\", \"Translate this from {source_lang} to {target_lang}: {text}\")\n",
    "    ])\n",
    "\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "# 체인 실행\n",
    "chain = translation_prompt | llm\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"source_lang\": \"English\",\n",
    "    \"target_lang\": \"Korean\", \n",
    "    \"text\": \"LangChain is a powerful framework for building AI applications.\"\n",
    "})\n",
    "\n",
    "print(\"Upstage Response:\")\n",
    "print(response.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "# using chain\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant that translates English to Korean.\"),\n",
    "        (\"human\", \"Translate this sentence from English to Korean. {english_text}.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatUpstage()\n",
    "chain = prompt | llm\n",
    "\n",
    "ai_message=chain.invoke({\"english_text\": \"Hello, How are you?\"})\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Groundness Check\n",
    "Groundedness Check API는 사용자가 제공한 Context(컨텍스트)에 대한 AI 어시스턴트의 응답이 실제로 그 컨텍스트에 기반하고 있는지 여부를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grounded\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "\n",
    "groundedness_check = UpstageGroundednessCheck()\n",
    "\n",
    "request_input = {\n",
    "    \"context\": \"삼성전자는 연결 기준으로 매출 74.07조원, 영업이익 10.44조원의 2024년 2분기 실적을 발표했다. 전사 매출은 전분기 대비 3% 증가한 74.07조원을 기록했다. DS부문은 메모리 업황 회복으로 전분기 대비 23% 증가하고, SDC는 OLED 판매 호조로 증가했다.\",\n",
    "    \"answer\": \"삼성전자의 2024년 2분기 매출은 약 74.07조원이다.\",\n",
    "}\n",
    "\n",
    "response = groundedness_check.invoke(request_input)\n",
    "print(response)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UpstageEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "doc_result = embeddings.embed_documents(\n",
    "    [\"Sung is a professor.\", \"This is another document\"]\n",
    ")\n",
    "print(doc_result)\n",
    "\n",
    "query_result = embeddings.embed_query(\"What does Sung do?\")\n",
    "print(query_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
